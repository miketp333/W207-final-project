{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA/Cluster Notebook\n",
    "[Return to project overview](final_project_overview.ipynb)\n",
    "\n",
    "### Andrew Larimer, Deepak Nagaraj, Daniel Olmstead, Michael Winton (W207-4-Summer 2018 Final Project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from util import our_train_test_split\n",
    "\n",
    "# set default options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned dataset\n",
    "merged_df = pd.read_csv('data_merged/combined_data_2018-07-18.csv')\n",
    "\n",
    "# Keep the numeric columns.\n",
    "features_to_keep = [\n",
    "                    'high_registrations',\n",
    "                    #'district', \n",
    "                    #'zip',\n",
    "                    'community_school', \n",
    "                    'economic_need_index', \n",
    "                    #'school_income_estimate',\n",
    "                    'percent_ell', \n",
    "                    'percent_asian', \n",
    "                    'percent_black', \n",
    "                    'percent_hispanic',\n",
    "                    'percent_black__hispanic', \n",
    "                    'percent_white', \n",
    "                    'student_attendance_rate',\n",
    "                    'percent_of_students_chronically_absent',\n",
    "                    'rigorous_instruction_percent', \n",
    "                    'rigorous_instruction_rating',\n",
    "                    'collaborative_teachers_percent', \n",
    "                    'collaborative_teachers_rating',\n",
    "                    'supportive_environment_percent', \n",
    "                    'supportive_environment_rating',\n",
    "                    'effective_school_leadership_percent',\n",
    "                    'effective_school_leadership_rating',\n",
    "                    'strong_family_community_ties_percent',\n",
    "                    'strong_family_community_ties_rating', \n",
    "                    'trust_percent', \n",
    "                    'trust_rating',\n",
    "                    'student_achievement_rating', \n",
    "                    'average_ela_proficiency',\n",
    "                    'average_math_proficiency', \n",
    "                    'grade_7_ela_all_students_tested',\n",
    "                    'grade_7_ela_4s_all_students',\n",
    "                    'grade_7_ela_4s_american_indian_or_alaska_native',\n",
    "                    'grade_7_ela_4s_black_or_african_american',\n",
    "                    'grade_7_ela_4s_hispanic_or_latino',\n",
    "                    'grade_7_ela_4s_asian_or_pacific_islander', \n",
    "                    'grade_7_ela_4s_white',\n",
    "                    'grade_7_ela_4s_multiracial',\n",
    "                    'grade_7_ela_4s_limited_english_proficient',\n",
    "                    'grade_7_ela_4s_economically_disadvantaged',\n",
    "                    'grade_7_math_all_students_tested', \n",
    "                    'grade_7_math_4s_all_students',\n",
    "                    'grade_7_math_4s_american_indian_or_alaska_native',\n",
    "                    'grade_7_math_4s_black_or_african_american',\n",
    "                    'grade_7_math_4s_hispanic_or_latino',\n",
    "                    'grade_7_math_4s_asian_or_pacific_islander', \n",
    "                    'grade_7_math_4s_white',\n",
    "                    'grade_7_math_4s_multiracial',\n",
    "                    'grade_7_math_4s_limited_english_proficient',\n",
    "                    'grade_7_math_4s_economically_disadvantaged',\n",
    "                    'number_of_students_english', \n",
    "                    'number_of_students_math',\n",
    "                    'number_of_students_science', \n",
    "                    'number_of_students_social_studies',\n",
    "                    'number_of_classes_english', \n",
    "                    'number_of_classes_math',\n",
    "                    'number_of_classes_science', \n",
    "                    'number_of_classes_social_studies',\n",
    "                    'average_class_size_english', \n",
    "                    'average_class_size_math',\n",
    "                    'average_class_size_science',\n",
    "                    'average_class_size_social_studies',\n",
    "                    'school_pupil_teacher_ratio'\n",
    "                   ]\n",
    "\n",
    "X = merged_df[features_to_keep]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['high_registrations']\n",
    "X = X.drop(['high_registrations'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values=np.nan, strategy='mean')\n",
    "X_i = pd.DataFrame(imp.fit_transform(X))\n",
    "X_i.columns = X.columns\n",
    "X_i.index = X.index\n",
    "X_i.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the full dataset into high and low-registrant\n",
    "X_pos = X_i[y==1]\n",
    "X_neg = X_i[y==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import util\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = our_train_test_split(X_i, y, stratify = y)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split just the training data into high and low-registrant\n",
    "train_pos = train_data[train_labels==1]\n",
    "train_neg = train_data[train_labels==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X_i)\n",
    "\n",
    "pca = SparsePCA(n_components=2, alpha=2, random_state=207)\n",
    "pc = pca.fit_transform(scaled_X)\n",
    "pcdf = pd.DataFrame(data = pc, columns=['pc1', 'pc2'])\n",
    "\n",
    "# Attach labels\n",
    "pcdf = pd.concat([pcdf, y], axis=1)\n",
    "\n",
    "# Plot the Results\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlabel('Principal Component 1', fontsize=15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize=15)\n",
    "ax.set_title('2-component PCA for SHSAT Registration', fontsize=20)\n",
    "ax.scatter(pcdf.loc[pcdf['high_registrations']==1, 'pc1'], pcdf.loc[pcdf['high_registrations']==1, 'pc2'], c='blue', s=50)\n",
    "ax.scatter(pcdf.loc[pcdf['high_registrations']==0, 'pc1'], pcdf.loc[pcdf['high_registrations']==0, 'pc2'], c='red', s=50)\n",
    "ax.legend(['High Registrations', 'Low Registrations'])\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "scaled_train_X = scaler.fit_transform(train_data)\n",
    "scaled_test_X = scaler.fit_transform(test_data)\n",
    "\n",
    "pca = SparsePCA(n_components=2, alpha=2, random_state=207)\n",
    "pc = pca.fit_transform(scaled_train_X)\n",
    "\n",
    "# Filter out the positive (poisonous) results\n",
    "pc_pos = pc[train_labels==1]\n",
    "# Filter out the negative (non-poisonous) results\n",
    "pc_neg = pc[train_labels==0]\n",
    "\n",
    "# Fit a GMM for the positive examples\n",
    "clfpos = GaussianMixture(n_components=4, covariance_type='full', random_state=207)\n",
    "clfpos.fit(pc_pos)\n",
    "# Fit a GMM for the negative examples\n",
    "clfneg = GaussianMixture(n_components=4, covariance_type='full', random_state=207)\n",
    "clfneg.fit(pc_neg)\n",
    "\n",
    "# Run PCA on the test answer\n",
    "pca_test = pca.transform(scaled_test_X)\n",
    "# Filter out the positive and negative results from the test data\n",
    "pca_test_pos = pca_test[test_labels==1]\n",
    "pca_test_neg = pca_test[test_labels==0]\n",
    "# Obtain the log-likelihood score for each result in the positive and negative result set\n",
    "score1 = clfpos.score_samples(pca_test)\n",
    "score0 = clfneg.score_samples(pca_test)\n",
    "# Compare site of likelihood to create a results array that looks like the labels array, and compare those for accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(np.mean((score1 >= score0)==test_labels)*100))\n",
    "\n",
    "# The rest of this is to generate the plots\n",
    "# Create a result set like the test_labels array\n",
    "predicted_result = (score1 >= score0).astype(int)\n",
    "# Create sub-arrays for all the correct and incorrect answers\n",
    "pos_correct = np.logical_and(test_labels==1, predicted_result==1) # True Positives\n",
    "neg_correct = np.logical_and(test_labels==0, predicted_result==0) # True Negatives\n",
    "pos_wrong = np.logical_and(test_labels==0, predicted_result==1) # False Positives\n",
    "neg_wrong = np.logical_and(test_labels==1, predicted_result==0) # False NEgatives\n",
    "\n",
    "# Compare each of these to the PCA resultset\n",
    "pca_pred_pos_y = pca_test[pos_correct]\n",
    "pca_pred_neg_y = pca_test[neg_correct]\n",
    "pca_pred_pos_n = pca_test[pos_wrong]\n",
    "pca_pred_neg_n = pca_test[neg_wrong]\n",
    "\n",
    "# display predicted scores by the model as a contour plot\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "red_patch = mpatches.Patch(color='red', label='Classified Incorrectly')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Classified Correctly')\n",
    "rangex = np.linspace(-.15, .45)\n",
    "rangey = np.linspace(-.3, .2)\n",
    "rangeX, rangeY = np.meshgrid(rangex, rangey)\n",
    "XX = np.array([rangeX.ravel(), rangeY.ravel()]).T\n",
    "\n",
    "# Plot the positive results\n",
    "Z = abs(clfpos.score_samples(XX))\n",
    "Z = Z.reshape(rangeX.shape)\n",
    "\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.contour(rangeX, rangeY, Z, norm=LogNorm(vmin=1.0, vmax=20.0), levels=np.logspace(0, 2, 10))\n",
    "ax.set_title('Test Values plotted in Positive Training Space \\n (n_components=4, covariance_type=full)', fontsize=15)\n",
    "ax.scatter(pca_pred_pos_n[:, 0], pca_pred_pos_n[:, 1], 40, c='red')\n",
    "ax.scatter(pca_pred_pos_y[:, 0], pca_pred_pos_y[:, 1], 20, c='blue')\n",
    "ax.axis('equal')\n",
    "ax.legend(handles=[blue_patch, red_patch])\n",
    "ax.grid()\n",
    "\n",
    "# Plot the negative results\n",
    "Z2 = abs(clfneg.score_samples(XX))\n",
    "Z2 = Z2.reshape(rangeX.shape)\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.contour(rangeX, rangeY, Z2, norm=LogNorm(vmin=1.0, vmax=20.0), levels=np.logspace(0, 2, 10))\n",
    "ax.set_title('Test Values plotted in Negative Training Space \\n (n_components=4, covariance_type=full)', fontsize=15)\n",
    "ax.scatter(pca_pred_neg_n[:, 0], pca_pred_neg_n[:, 1], 40, c='red')\n",
    "ax.scatter(pca_pred_neg_y[:, 0], pca_pred_neg_y[:, 1], 20, c='blue')\n",
    "ax.legend(handles=[blue_patch, red_patch])\n",
    "ax.axis('equal')\n",
    "ax.grid()    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
