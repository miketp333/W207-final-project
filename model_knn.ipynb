{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors\n",
    "\n",
    "### Andrew Larimer, Deepak Nagaraj, Daniel Olmstead, Michael Winton\n",
    "\n",
    "#### W207-4-Summer 2018 Final Project\n",
    "\n",
    "[Return to project overview](final_project_overview.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we attempt to classify the PASSNYC data via K-Nearest Neighbors algorithm.  The idea is to use \"K-nearest neighbors\" classifier to \"learn\" schools that have high number of SHSAT registrations, and use that to predict on a test set.\n",
    "\n",
    "***\n",
    "\n",
    "### Reading data\n",
    "Let us do some initial imports and set up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import util\n",
    "\n",
    "# set default options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "k_folds = 5\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train-test split\n",
    "train_data, test_data, train_labels, test_labels = util.read_data()\n",
    "\n",
    "print(\"Train data shape: %s\" % str(train_data.shape))\n",
    "print(\"Test data shape: %s\" % str(test_data.shape))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection\n",
    "\n",
    "We will now select some features from the above dataset.\n",
    "\n",
    "We will ignore some categorical variables and variables that are highly correlated with outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    # non-numeric\n",
    "    'dbn',\n",
    "    # correlated with outcome variable\n",
    "    'num_shsat_test_takers',\n",
    "    'offers_per_student',\n",
    "    'pct_test_takers',\n",
    "    # demographic or correlated with demographics\n",
    "    'school_name',\n",
    "    'zip',\n",
    "    'district',\n",
    "    # too many nulls\n",
    "    'school_income_estimate',\n",
    "]\n",
    "perf_train_data = train_data.drop(drop_cols, axis=1)\n",
    "perf_train_data_nonull = perf_train_data.fillna(perf_train_data.mean())\n",
    "\n",
    "perf_test_data = test_data.drop(drop_cols, axis=1)\n",
    "perf_test_data_nonull = perf_test_data.fillna(perf_test_data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## K-Nearest Neighbors Classification\n",
    "\n",
    "#### Default run\n",
    "We will now run KNN prediction on the dataset, with the default K value (=5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(perf_train_data_nonull)\n",
    "rescaledX = scaler.transform(perf_train_data_nonull)\n",
    "y = train_labels\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Do k-fold cross-validation, collecting both \"test\" accuracy and F1 \n",
    "cv_scores = cross_validate(clf, rescaledX, y, cv=k_folds, scoring=['accuracy', 'f1'])\n",
    "util.print_cv_results(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching for best $k$\n",
    "We get accuracy of 82% and F1 score of 0.58.  Let us experiment with various values of $k$ to see which gives the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         KNeighborsClassifier())\n",
    "n_neighbors = list(range(1, 15))\n",
    "estimator = GridSearchCV(pipeline,\n",
    "                        dict(kneighborsclassifier__n_neighbors=n_neighbors),\n",
    "                        cv=k_folds, n_jobs=-1, scoring='f1')\n",
    "estimator.fit(perf_train_data_nonull, y)\n",
    "\n",
    "best_k = estimator.best_params_['kneighborsclassifier__n_neighbors']\n",
    "print(\"Best no. of neighbors: %d\" % best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best value for number of neighbors is $k=3$.  Let us get the scores for this value of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do k-fold cross-validation, collecting both \"test\" accuracy and F1 \n",
    "clf = KNeighborsClassifier(n_neighbors=best_k)\n",
    "cv_scores = cross_validate(clf, rescaledX, y, cv=k_folds, scoring=['accuracy', 'f1'])\n",
    "util.print_cv_results(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get accuracy of 85% and F1 of 0.64.  Let us run the above KNN model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         KNeighborsClassifier(n_neighbors=best_k))\n",
    "pipeline.fit(perf_train_data_nonull, train_labels)\n",
    "predicted_labels = pipeline.predict(perf_test_data_nonull)\n",
    "knn_score_accuracy = metrics.accuracy_score(test_labels, predicted_labels)\n",
    "knn_score_f1 = metrics.f1_score(test_labels, predicted_labels)\n",
    "\n",
    "print(\"On the test set, the model has an accuracy of {:.2f}% and an F1 score of {:.2f}.\"\n",
    "     .format(knn_score_accuracy*100, knn_score_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see accuracy of 87% on test set, and F1 of 0.73.\n",
    "\n",
    "We will later report the above two values: one for cross-validation, and another for test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "### KNN with select features\n",
    "\n",
    "We will now attempt to do some feature selection, followed by running KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         SelectFromModel(ExtraTreesClassifier(random_state=207)))\n",
    "pipeline.fit_transform(perf_train_data_nonull, y)\n",
    "selected_features = pipeline.steps[1][1].get_support()\n",
    "selected_cols = perf_train_data_nonull.columns[selected_features].values.tolist()\n",
    "print(\"Selected feature columns: %s\" % selected_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching for best $k$\n",
    "\n",
    "Let us also find the best number of neighbors for this subset of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         KNeighborsClassifier())\n",
    "n_neighbors = list(range(1, 15))\n",
    "estimator = GridSearchCV(pipeline,\n",
    "                        dict(kneighborsclassifier__n_neighbors=n_neighbors),\n",
    "                        cv=k_folds, n_jobs=-1, scoring='f1')\n",
    "\n",
    "perf_train_data_nonull_sel_cols = selected_cols\n",
    "perf_train_data_nonull_sel = perf_train_data_nonull[perf_train_data_nonull_sel_cols]\n",
    "estimator.fit(perf_train_data_nonull_sel, y)\n",
    "\n",
    "best_k = estimator.best_params_['kneighborsclassifier__n_neighbors']\n",
    "print(\"Best no. of neighbors: %d\" % best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this to run cross-validation on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(perf_train_data_nonull_sel)\n",
    "rescaledX_sel = scaler.transform(perf_train_data_nonull_sel)\n",
    "clf = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "# Do k-fold cross-validation, collecting both \"test\" accuracy and F1 \n",
    "cv_scores = cross_validate(clf, rescaledX_sel, y, cv=k_folds, scoring=['accuracy','f1'])\n",
    "util.print_cv_results(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score falls a little to 0.59.  Let us look at how it performs on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         KNeighborsClassifier(n_neighbors=best_k))\n",
    "pipeline.fit(perf_train_data_nonull_sel, y)\n",
    "perf_test_data_nonull_sel = perf_test_data_nonull[perf_train_data_nonull_sel_cols]\n",
    "predicted_labels = pipeline.predict(perf_test_data_nonull_sel)\n",
    "knn_score_accuracy = metrics.accuracy_score(test_labels, predicted_labels)\n",
    "knn_score_f1 = metrics.f1_score(test_labels, predicted_labels)\n",
    "\n",
    "print(\"On the test set, the model has an accuracy of {:.2f}% and an F1 score of {:.2f}.\"\n",
    "     .format(knn_score_accuracy*100, knn_score_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model does not do well on test set either.  Nevertheless, we will report this as a second run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### KNN with reduced dimensions\n",
    "\n",
    "We will next attempt to reduce dimensions via PCA, followed by KNN.\n",
    "\n",
    "First, we will attempt to find the best number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plot of variance explained vs # principale components\n",
    "util.get_num_pcas(perf_train_data_nonull, var_explained=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first 3 components already explain more than 70% of variance.  The slope of the graph goes down after this, indicating that remaining components are not as informative.\n",
    "\n",
    "#### Searching for best $k$\n",
    "\n",
    "Let us run GridSearch on both PCA components and K, to see if we can get a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         PCA(random_state=207),\n",
    "                         KNeighborsClassifier())\n",
    "\n",
    "n_components = list(range(1, 12))\n",
    "n_neighbors = list(range(1, 15))\n",
    "estimator = GridSearchCV(pipeline,\n",
    "                        dict(pca__n_components=n_components,\n",
    "                             kneighborsclassifier__n_neighbors=n_neighbors),\n",
    "                             cv=k_folds, scoring='f1')\n",
    "estimator.fit(perf_train_data_nonull, y)\n",
    "\n",
    "best_pca_components = estimator.best_params_['pca__n_components']\n",
    "best_k = estimator.best_params_['kneighborsclassifier__n_neighbors']\n",
    "print(\"Best no. of PCA components: %d, neighbors: %d\" % \n",
    "      (best_pca_components,\n",
    "       best_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that PCA with 8 components, followed by KNN with 7 neighbors is the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do k-fold cross-validation, collecting both \"test\" accuracy and F1 \n",
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         PCA(random_state=207, n_components=best_pca_components),\n",
    "                         KNeighborsClassifier(n_neighbors=best_k))\n",
    "\n",
    "cv_scores = cross_validate(pipeline, perf_train_data_nonull, train_labels, cv=k_folds, scoring=['accuracy', 'f1'])\n",
    "util.print_cv_results(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this combination, we get accuracy of 84% and F1 score of 0.63.  Let's run the above model on test set and determine our model scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         PCA(random_state=207, n_components=best_pca_components),\n",
    "                         KNeighborsClassifier(n_neighbors=best_k))\n",
    "pipeline.fit(perf_train_data_nonull, train_labels)\n",
    "predicted_labels = pipeline.predict(perf_test_data_nonull)\n",
    "lr_score_accuracy = metrics.accuracy_score(test_labels, predicted_labels)\n",
    "lr_score_f1 = metrics.f1_score(test_labels, predicted_labels)\n",
    "\n",
    "print(\"On the test set, the model has an accuracy of {:.2f}% and an F1 score of {:.2f}.\"\n",
    "     .format(lr_score_accuracy*100, lr_score_f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get accuracy of 88% and a rather good F1 score of 0.73.  The accuracy improves a tiny bit on test set, but falls a bit in 5-fold cross-validation.\n",
    "\n",
    "Let us summarize our three runs of KNN so far.\n",
    "\n",
    "***\n",
    "\n",
    "### Summary\n",
    "\n",
    "Model | CV Accuracy | (95% CI) | CV F1 | (95% CI) | Test Set Accuracy | Test Set F1\n",
    ":---|:---:|:---:|:---:|:---:|:---:|:---:\n",
    "K-Nearest Neighbors (Full Model) | 0.849 | (0.721, 0.976) | 0.637 | (0.328, 0.946) | 0.87 | 0.73\n",
    "K-Nearest Neighbors (Top n Features) | 0.841 | (0.756, 0.926) | 0.586 | (0.376, 0.795) | 0.84 | 0.65\n",
    "K-Nearest Neighbors (PCA, most features) | 0.841 | (0.714, 0.967) | 0.630 | (0.357, 0.903) | 0.88 | 0.73\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### List of schools for PASSNYC\n",
    "\n",
    "Let us look at what schools the model classified as positive, but were actually negative.  These are the schools we should target, because the model thinks they should have high SHSAT registrations, but in reality they do not.\n",
    "\n",
    "We will use the last model run above (PCA, most features) to generate the school list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(StandardScaler(),\n",
    "                         PCA(n_components=best_pca_components, random_state=207),\n",
    "                         KNeighborsClassifier(n_neighbors=best_k))\n",
    "\n",
    "fp_df = util.run_model_get_ordered_predictions(pipeline, train_data, test_data,\n",
    "                                               perf_train_data_nonull, perf_test_data_nonull,\n",
    "                                               train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the false positives, we will obtain a ranking of the schools that we can provide to PASSNYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_passnyc = util.create_passnyc_list(fp_df, train_data, test_data,\n",
    "                                 train_labels, test_labels)\n",
    "# Write to CSV\n",
    "df_passnyc.to_csv('results/results.knn.csv')\n",
    "\n",
    "df_passnyc"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
