{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors\n",
    "[Return to project overview](final_project_overview.ipynb)\n",
    "\n",
    "### Andrew Larimer, Deepak Nagaraj, Daniel Olmstead, Michael Winton (W207-4-Summer 2018 Final Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we attempt to classify the PASSNYC data via K-Nearest Neighbors algorithm.\n",
    "\n",
    "### Reading data\n",
    "Let us do some initial imports and set up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util\n",
    "\n",
    "\n",
    "# set default options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "# Get train-test split\n",
    "train_data, test_data, train_labels, test_labels = util.read_data()\n",
    "\n",
    "print(\"Train data shape: %s\" % str(train_data.shape))\n",
    "print(\"Test data shape: %s\" % str(test_data.shape))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "We will now select some features from the above dataset.\n",
    "\n",
    "Let us shortlist some interesting columns:\n",
    "* dbn\n",
    "* rigorous_instruction_percent\n",
    "* rigorous_instruction_rating\n",
    "* collaborative_teachers_percent\n",
    "* collaborative_teachers_rating\n",
    "* supportive_environment_percent\n",
    "* supportive_environment_rating\n",
    "* effective_school_leadership_percent\n",
    "* effective_school_leadership_rating\n",
    "* strong_family_community_ties_percent\n",
    "* strong_family_community_ties_rating\n",
    "* trust_percent\n",
    "* trust_rating\n",
    "* student_achievement_rating\n",
    "* average_ela_proficiency\n",
    "* average_math_proficiency\n",
    "* grade_7_ela_all_students_tested\n",
    "* grade_7_ela_4s_all_students\n",
    "* grade_7_math_all_students_tested\n",
    "* grade_7_math_4s_all_students\n",
    "* average_class_size_english\n",
    "* average_class_size_math\n",
    "* school_pupil_teacher_ratio\n",
    "* student_attendance_rate\n",
    "\n",
    "We ignore the following demographic indicators:\n",
    "* school_name\n",
    "* zip\n",
    "* community_school\n",
    "* economic_need_index\n",
    "* school_income_estimate\n",
    "* percent_ell\n",
    "* percent_black\n",
    "* percent_hispanic\n",
    "* percent_asian\n",
    "* percent_white\n",
    "* percent_of_students_chronically_absent\n",
    "\n",
    "We also ignore the following columns because they proxy output variable:\n",
    "* num_shsat_test_takers\n",
    "* offers_per_student\n",
    "* pct_test_takers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate this list again:\n",
    "# Take above (markdown) list and store it in say ~/tmp/col_list.  Then:\n",
    "# cat  ~/tmp/col_list | cut -d\" \" -f2 | sed -E 's/^(.*)$/\"\\1\"/' | tr '\\n' ', '\n",
    "\n",
    "perf_train_data = train_data[[\"rigorous_instruction_percent\",\"rigorous_instruction_rating\",\"collaborative_teachers_percent\",\"collaborative_teachers_rating\",\"supportive_environment_percent\",\"supportive_environment_rating\",\"effective_school_leadership_percent\",\"effective_school_leadership_rating\",\"strong_family_community_ties_percent\",\"strong_family_community_ties_rating\",\"trust_percent\",\"trust_rating\",\"student_achievement_rating\",\"average_ela_proficiency\",\"average_math_proficiency\",\"grade_7_ela_all_students_tested\",\"grade_7_ela_4s_all_students\",\"grade_7_math_all_students_tested\",\"grade_7_math_4s_all_students\",\"average_class_size_english\",\"average_class_size_math\",\"school_pupil_teacher_ratio\",\"student_attendance_rate\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "We will first run PCA to see if we can reduce the dimensions significantly.  It seems like 3 dimensions are enough for variance ratio to be > 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "perf_train_data_nonull = perf_train_data.fillna(perf_train_data.mean())\n",
    "cum_explained_variance_ratios = []\n",
    "for n in range(1, 15):\n",
    "    pipeline = make_pipeline(StandardScaler(), \n",
    "                            PCA(n_components=n, random_state=207))\n",
    "    pipeline.fit_transform(perf_train_data_nonull)\n",
    "    pca = pipeline.steps[1][1]\n",
    "    cum_explained_variance_ratios.append(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.plot(np.array(cum_explained_variance_ratios))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Model\n",
    "\n",
    "Next, we try to select N-best features, based on univariate statistical tests.  We use the $\\chi^2$ test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pipeline = make_pipeline(MinMaxScaler(), \n",
    "                         SelectKBest(chi2, k=5))\n",
    "pipeline.fit_transform(perf_train_data_nonull, train_labels)\n",
    "selected_features = pipeline.steps[1][1].get_support()\n",
    "perf_train_data_nonull.columns[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The univariate _KBest_ model selects the following features, for $K = 5$:\n",
    "* Average ELA proficiency\n",
    "* Average math proficiency\n",
    "* Grade 7 ELA all students\n",
    "* Grade 7 math 4S all students\n",
    "* Student attendance rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model\n",
    "\n",
    "We next run a linear model with L1 penalty and regularization (C) to select features.  Let us see what features it selects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         SelectFromModel(LinearSVC(C=0.05, penalty='l1', dual=False, random_state=207)))\n",
    "pipeline.fit_transform(perf_train_data_nonull, train_labels)\n",
    "selected_features = pipeline.steps[1][1].get_support()\n",
    "perf_train_data_nonull.columns[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the SVM model selects the following features:\n",
    "\n",
    "* Collaborative teachers rating\n",
    "* Average math proficiency\n",
    "* Grade 7 ELA 4S all students\n",
    "* Grade 7 math 4S all students\n",
    "* Student attendance rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-based Model\n",
    "\n",
    "Let us now run a tree-based estimator to see which features it selects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         SelectFromModel(ExtraTreesClassifier()))\n",
    "pipeline.fit_transform(perf_train_data_nonull, train_labels)\n",
    "selected_features = pipeline.steps[1][1].get_support()\n",
    "perf_train_data_nonull.columns[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model selects the following features:\n",
    "* Average ELA proficiency\n",
    "* Average math proficiency\n",
    "* Grade 7 ELA 4S all students\n",
    "* Grade 7 math all students\n",
    "* Grade 7 math 4S all students\n",
    "* School pupil teacher ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final selection\n",
    "\n",
    "Considering all the features above, we can now select a final set of features.\n",
    "\n",
    "The following are in 1+ models, so we will select them:\n",
    "* Grade 7 math 4S all students\n",
    "* Grade 7 ELA 4S all students\n",
    "* Average math proficiency\n",
    "* Average ELA proficiency\n",
    "* Student attendance rate\n",
    "\n",
    "The following are columns we will keep as a backup:\n",
    "* School pupil teacher ratio\n",
    "* Grade 7 math all students\n",
    "* Collaborative teachers rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Classification\n",
    "\n",
    "We will now run KNN prediction on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "selected_features = ['grade_7_math_4s_all_students',\n",
    "                     'grade_7_ela_4s_all_students', \n",
    "                     'average_math_proficiency',\n",
    "                     'average_ela_proficiency',\n",
    "                     'student_attendance_rate']\n",
    "perf_train_data_nonull_knn = perf_train_data_nonull[selected_features]\n",
    "\n",
    "scaler = StandardScaler().fit(perf_train_data_nonull_knn)\n",
    "rescaledX = scaler.transform(perf_train_data_nonull_knn)\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Do k-fold cross-validation, collecting both \"test\" accuracy and F1 \n",
    "k_folds = 10\n",
    "cv_scores = cross_validate(clf, rescaledX, train_labels, cv=k_folds, scoring=['accuracy','f1'])\n",
    "util.print_cv_results(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The KNN model gives good results for low-registrations, but not for high-registrations.  There is also sparse data for \"high registrations\", as shown by the \"support\" column.  We may be better off using an ensemble technique to avoid giving undue weightage to a single classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
