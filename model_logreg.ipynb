{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Notebook\n",
    "[Return to project overview](final_project_overview.ipynb)\n",
    "\n",
    "### Andrew Larimer, Deepak Nagaraj, Daniel Olmstead, Michael Winton (W207-4-Summer 2018 Final Project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util\n",
    "from util import our_train_test_split\n",
    "\n",
    "# set default options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and split class labels into separate array\n",
    "\n",
    "Our utility function reads the merged dataset, imputes the column mean for missing numeric values, and then performs a stratified train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the \"production\" version of the cleaned & merged dataset\n",
    "train_data_orig, test_data_orig, train_labels, test_labels = util.read_data(do_imputation=True)\n",
    "print(train_data_orig.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter to the columns that we will use in the model.  `district` and `zip`, while numeric, do not hold mathematical meaning and reduce accuracy and interpretability (it makes no sense to say that the higher or lower your district, the more or less likely you are to be a high-registering school).  `school_income_estimate` is too sparse to be be useful.  These columns are dropped from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [\n",
    "                    #'district', \n",
    "                    #'zip',\n",
    "                    'community_school', \n",
    "                    'economic_need_index', \n",
    "                    #'school_income_estimate',\n",
    "                    'grade_7_enrollment',\n",
    "                    'percent_ell', \n",
    "                    'percent_asian', \n",
    "                    'percent_black', \n",
    "                    'percent_hispanic',\n",
    "                    'percent_black__hispanic', \n",
    "                    'percent_white', \n",
    "                    'student_attendance_rate',\n",
    "                    'percent_of_students_chronically_absent',\n",
    "                    'rigorous_instruction_percent', \n",
    "                    'rigorous_instruction_rating',\n",
    "                    'collaborative_teachers_percent', \n",
    "                    'collaborative_teachers_rating',\n",
    "                    'supportive_environment_percent', \n",
    "                    'supportive_environment_rating',\n",
    "                    'effective_school_leadership_percent',\n",
    "                    'effective_school_leadership_rating',\n",
    "                    'strong_family_community_ties_percent',\n",
    "                    'strong_family_community_ties_rating', \n",
    "                    'trust_percent', \n",
    "                    'trust_rating',\n",
    "                    'student_achievement_rating', \n",
    "                    'average_ela_proficiency',\n",
    "                    'average_math_proficiency', \n",
    "                    'grade_7_ela_all_students_tested',\n",
    "                    'grade_7_ela_4s_all_students',\n",
    "                    'grade_7_ela_4s_american_indian_or_alaska_native',\n",
    "                    'grade_7_ela_4s_black_or_african_american',\n",
    "                    'grade_7_ela_4s_hispanic_or_latino',\n",
    "                    'grade_7_ela_4s_asian_or_pacific_islander', \n",
    "                    'grade_7_ela_4s_white',\n",
    "                    'grade_7_ela_4s_multiracial',\n",
    "                    'grade_7_ela_4s_limited_english_proficient',\n",
    "                    'grade_7_ela_4s_economically_disadvantaged',\n",
    "                    'grade_7_math_all_students_tested', \n",
    "                    'grade_7_math_4s_all_students',\n",
    "                    'grade_7_math_4s_american_indian_or_alaska_native',\n",
    "                    'grade_7_math_4s_black_or_african_american',\n",
    "                    'grade_7_math_4s_hispanic_or_latino',\n",
    "                    'grade_7_math_4s_asian_or_pacific_islander', \n",
    "                    'grade_7_math_4s_white',\n",
    "                    'grade_7_math_4s_multiracial',\n",
    "                    'grade_7_math_4s_limited_english_proficient',\n",
    "                    'grade_7_math_4s_economically_disadvantaged',\n",
    "                    'sie_provided',\n",
    "                    'in_bronx',\n",
    "                    'in_brooklyn',\n",
    "                    'in_manhattan',\n",
    "                    'in_queens',\n",
    "                    'in_staten',\n",
    "                    'number_of_students_english', \n",
    "                    'number_of_students_math',\n",
    "                    'number_of_students_science', \n",
    "                    'number_of_students_social_studies',\n",
    "                    'number_of_classes_english', \n",
    "                    'number_of_classes_math',\n",
    "                    'number_of_classes_science', \n",
    "                    'number_of_classes_social_studies',\n",
    "                    'average_class_size_english', \n",
    "                    'average_class_size_math',\n",
    "                    'average_class_size_science',\n",
    "                    'average_class_size_social_studies',\n",
    "                    'school_pupil_teacher_ratio',\n",
    "                    'gifted',\n",
    "                    'selective'\n",
    "                   ]\n",
    "\n",
    "train_data = train_data_orig[features_to_keep]\n",
    "test_data = test_data_orig[features_to_keep]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "Find the optimal C-score and penalty using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "\n",
    "lr = LogisticRegression(random_state=207)\n",
    "penalty = ['l1', 'l2']\n",
    "C = [0.01, 0.05, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 1.000, 2.000, 3.000, 4.000]\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "clf = GridSearchCV(lr, hyperparameters, cv=5, verbose=0)\n",
    "best_model = clf.fit(train_data_scaled, train_labels)\n",
    "best_penalty = best_model.best_estimator_.get_params()['penalty']\n",
    "best_c = best_model.best_estimator_.get_params()['C']\n",
    "print('Best Penalty:', best_penalty)\n",
    "print('Best C:', best_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Pipeline and K-fold validation\n",
    "Using five k-folds and the optimal hyperparameters from above, determine the overall accuracy and F1 score for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(C=best_c, penalty=best_penalty, random_state=207))\n",
    "k_folds = 5\n",
    "cv_scores = cross_validate(pipe, train_data, train_labels, cv=k_folds, scoring=['accuracy','f1'])\n",
    "cv_f1 = cv_scores['test_f1'].mean()\n",
    "util.print_cv_results(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model to the test set\n",
    "Check for overfitting by applying the model to the test set and reporting back accuracy and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "lr = LogisticRegression(C=best_c, penalty=best_penalty, random_state=207)\n",
    "train_data_scaled, test_data_scaled = scaler.fit_transform(train_data), scaler.fit_transform(test_data)\n",
    "lr.fit(train_data_scaled, train_labels)\n",
    "predicted_labels = lr.predict(test_data_scaled)\n",
    "lr_score_accuracy = metrics.accuracy_score(test_labels, predicted_labels)\n",
    "lr_score_f1 = metrics.f1_score(test_labels, predicted_labels)\n",
    "\n",
    "print(\"On the test set, the model has an accuracy of {:.2f}% and an F1 score of {:.2f}.\"\n",
    "     .format(lr_score_accuracy*100, lr_score_f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine coefficients\n",
    "For a better understanding of the model, including which factors are most important for predicting a high-registering school, we turn to an analysis of the model coefficients.  As the goal here is not prediction but comprehension, the first step is to recombine the data into a set that contains 100% of the schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recombine train and test data into an aggregate dataset\n",
    "X_orig = pd.concat([train_data_orig, test_data_orig])\n",
    "X_i = pd.concat([train_data, test_data])\n",
    "y = np.concatenate((train_labels,test_labels))\n",
    "X_pos = X_i[y==1]\n",
    "X_neg = X_i[y==0]\n",
    "X_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Run coefficient analysis on 100% of the data\n",
    "np_train_data = np.array(scaler.fit_transform(X_i))\n",
    "np_train_labels = y\n",
    "\n",
    "# Run k-fold cross-validation with 5 folds 10 times, which means every school is predicted 10 times.\n",
    "folds = 5\n",
    "repeats = 10\n",
    "rskf = RepeatedStratifiedKFold(n_splits=folds, n_repeats= repeats, random_state=207)\n",
    "fold_list = []\n",
    "\n",
    "# Build multiple dataframes from the results, with columns for each k-fold\n",
    "for f in range(1, (folds*repeats)+1):\n",
    "    fold_list.append('k{}'.format(f))\n",
    "# This contains the coefficients for every feature in every test\n",
    "coefs = pd.DataFrame(index=train_data.columns, columns=fold_list)\n",
    "# This contains the predicted value for each school tested (20% of the dataset each time)\n",
    "predictions = pd.DataFrame(index=X_i.index, columns = fold_list)\n",
    "# This contains the probabilities that each tested school will be a 0 or a 1, for use in later analysis\n",
    "probs_0 = pd.DataFrame(index=X_i.index, columns = fold_list)\n",
    "probs_1 = pd.DataFrame(index=X_i.index, columns = fold_list)\n",
    "\n",
    "# Iterate through the Repeated Stratified K Fold, and and fill out the DataFrames\n",
    "counter = 1\n",
    "for train, test in rskf.split(np_train_data, np_train_labels):\n",
    "    log = LogisticRegression(C=best_c, penalty=best_penalty, random_state=207)\n",
    "    log.fit(np_train_data[train], np_train_labels[train])\n",
    "    predicted_labels = log.predict(np_train_data[test])\n",
    "    predicted_probs = log.predict_proba(np_train_data[test])\n",
    "    coefs['k{}'.format(counter)] = log.coef_[0]\n",
    "    predictions.iloc[test, counter-1] = predicted_labels\n",
    "    probs_0.iloc[test, counter-1] = predicted_probs[:,0]\n",
    "    probs_1.iloc[test, counter-1] = predicted_probs[:,1]\n",
    "    counter += 1\n",
    "\n",
    "# Find the average coefficient across all 50 regressions, and sort descending\n",
    "coefs['avg'] = coefs.mean(axis=1)\n",
    "sorted_coefs = coefs.sort_values(by='avg', ascending=False)\n",
    "sorted_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "### Most positively-influential features\n",
    "Using the average coefficients, we can discover the features that have the greatest effect in predicting both a 1 (positive) or a zero (negative).  Histograms can show us the different distributions for high-registering and low-registering schools in these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top and bottom 5 most influential coefficients\n",
    "top_features, bottom_features = list(sorted_coefs.index[:6]), list(sorted_coefs.index[-6:])\n",
    "fig = plt.figure(figsize=(20,60))\n",
    "for c in top_features:\n",
    "    ax = fig.add_subplot(6,2,top_features.index(c)+1)\n",
    "    ax.set_title('Distribution for {}'.format(c), fontsize=17)\n",
    "    ax.hist(X_pos[c], bins=20, alpha=0.5, label=\"high registrants\", density=True)\n",
    "    ax.hist(X_neg[c], bins=20, alpha=0.5, label=\"low registrants\", density=True)\n",
    "    ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most negatively-influential features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,60))\n",
    "for c in bottom_features:\n",
    "    ax = fig.add_subplot(6,2,bottom_features.index(c)+1)\n",
    "    ax.set_title('Distribution for {}'.format(c), fontsize=17)\n",
    "    ax.hist(X_pos[c], bins=20, alpha=0.5, label=\"high registrants\", density=True)\n",
    "    ax.hist(X_neg[c], bins=20, alpha=0.5, label=\"low registrants\", density=True)\n",
    "    ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Wrong Answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax = sns.regplot(X_pos.grade_7_math_4s_hispanic_or_latino, X_pos.grade_7_ela_4s_hispanic_or_latino, label=\"High Registrations\")\n",
    "ax = sns.regplot(X_neg.grade_7_math_4s_hispanic_or_latino, X_neg.grade_7_ela_4s_hispanic_or_latino, label=\"Low Registrations\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax = sns.regplot(X_i.grade_7_math_4s_hispanic_or_latino, y, logistic=True, label=\"Math\")\n",
    "ax = sns.regplot(X_i.grade_7_ela_4s_hispanic_or_latino, y, logistic=True, label=\"English\")\n",
    "ax.set_xlabel('Number of Students achieving a score of 4', fontsize=15)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax = sns.regplot(X_i.percent_asian, y, logistic=True, label=\"% Asian\")\n",
    "ax = sns.regplot(X_i.percent_hispanic, y, logistic=True, label=\"% Hispanic\")\n",
    "ax.set_xlabel('Percent of school either Asian or Hispanic', fontsize=15)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax = sns.regplot(X_i.economic_need_index, y, logistic=True, label=\"Economic Need Index\")\n",
    "ax.set_xlabel('Economic Need Index', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.set_title('Distribution for {}'.format('Economic Need Index'), fontsize=17)\n",
    "ax.hist(X_pos['economic_need_index'], bins=20, alpha=0.5, label=\"high registrants\", density=True)\n",
    "ax.hist(X_neg['economic_need_index'], bins=20, alpha=0.5, label=\"low registrants\", density=True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap Analysis\n",
    "We can build a table of all the kfold predictions, and see the degree to which the model got each school right or wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['1s'] = predictions.iloc[:,:50].sum(axis=1)\n",
    "predictions['0s'] = (predictions.iloc[:,:50]==0).sum(axis=1)\n",
    "predictions['true'] = y\n",
    "\n",
    "predictions['1_prob'] = probs_1.mean(axis=1)\n",
    "predictions['0_prob'] = probs_0.mean(axis=1)\n",
    "predictions = predictions.sort_values(by=['1_prob'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of raw results, along with the number of votes each received and the true value\n",
    "X_predicted = pd.concat([X_i, predictions['1s'], predictions['0s'], predictions['true'], predictions['1_prob']], axis=1, join_axes=[X_i.index])\n",
    "# Rename the y columns to be more descriptive\n",
    "X_predicted.rename(columns={0:\"high_registrations\"}, inplace=True)\n",
    "# Sort by number of votes, most votes for 1 at the top and most votes for 0 at the bottom\n",
    "X_predicted = X_predicted.sort_values(by=['1_prob'], ascending=False)\n",
    "\n",
    "# Normalize the values of the data columns\n",
    "scaled_X_predicted = scaler.fit_transform(X_predicted)\n",
    "# Multiply the normalized value by the average coefficient to get a weighted influence score\n",
    "avg_coefs = np.array(coefs['avg'])\n",
    "weighted_values = np.multiply(scaled_X_predicted[:, :-4], avg_coefs)\n",
    "# Make a new copy of the results dataframe, and paste in the scaled values for the data columns\n",
    "X_result_weighted = X_predicted.copy()\n",
    "X_result_weighted.iloc[:, :-4] = weighted_values\n",
    "# Manually scale the vote columns to between -1.5 and 1.5 so they don't overweight the heatmap\n",
    "X_result_weighted.iloc[:, -4:-3] = predictions['1_prob']\n",
    "X_result_weighted.iloc[:, -3:-2] = predictions['0_prob']\n",
    "X_result_weighted = X_result_weighted.sort_values(by=['1s', '0s'], ascending=[False, True])\n",
    "#X_predicted = X_predicted.set_index(X_result_weighted.index)\n",
    "\n",
    "#X_result_weighted.iloc[:, -3:-1] = np.multiply(X_predicted.iloc[:,-3:-1], .15)\n",
    "\n",
    "# Check the variation in every column, and drop the columns that don't show much effect on the result\n",
    "drop_cols = ['1_prob']\n",
    "for c in X_result_weighted.columns:\n",
    "    if X_result_weighted[c].max() - X_result_weighted[c].min() < .6:\n",
    "        drop_cols.append(c)\n",
    "X_result_weighted_trimmed = X_result_weighted.drop(drop_cols, axis=1)\n",
    "X_result_weighted_trimmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,200))\n",
    "fig.patch.set_facecolor('white')\n",
    "im = ax.imshow(X_result_weighted_trimmed, cmap='viridis')\n",
    "ax.xaxis.tick_top()\n",
    "ax.set_xticks(np.arange(len(X_result_weighted_trimmed.columns)))\n",
    "ax.set_yticks(np.arange(len(X_result_weighted_trimmed.index)))\n",
    "ax.set_xticklabels(X_result_weighted_trimmed.columns)\n",
    "labels = X_orig.loc[:,'school_name'].reindex([X_result_weighted_trimmed.index])\n",
    "ax.set_yticklabels(labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=90, ha=\"left\", va=\"center\", rotation_mode=\"anchor\")\n",
    "\n",
    "for i in range(len(X_result_weighted_trimmed.index)):\n",
    "    for j in range(len(X_result_weighted_trimmed.columns[1:])+1):\n",
    "        text = ax.text(j, i, \"{:n}\".format(round(X_predicted.loc[X_result_weighted_trimmed.index[i], X_result_weighted_trimmed.columns[j]], 0)),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is perhaps most useful to examine the false positives - that is, schools that did NOT have high SHSAT registrations, but that the model thought SHOULD have.  We'll put the threshhold at 5 or more incorrect \"true\" classifications, and rank them in descending order (ie, the schools the model got most consistently wrong at the top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = predictions[predictions['true']==0]\n",
    "false_positives = false_positives[false_positives['1s'] > 5]['1s']\n",
    "\n",
    "fp_result = pd.concat([false_positives, X_i], axis=1, join='inner')\n",
    "fp_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_fp_X = scaler.fit_transform(fp_result.iloc[:,1:])\n",
    "avg_coefs = np.array(coefs['avg'])\n",
    "weighted_values = np.multiply(scaled_fp_X, avg_coefs)\n",
    "fp_result_weighted = fp_result.copy()\n",
    "fp_result_weighted.iloc[:, 1:] = weighted_values\n",
    "# Drop the columns that don't have any evidence of influential values\n",
    "drop_cols = []\n",
    "for c in fp_result_weighted.columns:\n",
    "    if fp_result_weighted[c].max() - fp_result_weighted[c].min() < .5:\n",
    "        drop_cols.append(c)\n",
    "fp_result_weighted_trimmed = fp_result_weighted.drop(drop_cols, axis=1)\n",
    "fp_result_weighted_trimmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,20))\n",
    "im = ax.imshow(fp_result_weighted_trimmed.iloc[:,1:], cmap='viridis')\n",
    "ax.xaxis.tick_top()\n",
    "ax.set_xticks(np.arange(len(fp_result_weighted_trimmed.columns[1:])))\n",
    "ax.set_yticks(np.arange(len(fp_result_weighted_trimmed.index)))\n",
    "ax.set_xticklabels(fp_result_weighted_trimmed.columns[1:])\n",
    "labels = X_orig.loc[:,'school_name'].reindex([fp_result_weighted_trimmed.index])\n",
    "ax.set_yticklabels(labels)\n",
    "#ax.set_yticklabels(fp_result_weighted_trimmed.index)\n",
    "plt.setp(ax.get_xticklabels(), rotation=90, ha=\"left\", va=\"center\", rotation_mode=\"anchor\")\n",
    "\n",
    "for i in range(len(fp_result_weighted_trimmed.index)):\n",
    "    for j in range(len(fp_result_weighted_trimmed.columns[1:])):\n",
    "        text = ax.text(j, i, round(fp_result.loc[fp_result_weighted_trimmed.index[i], fp_result_weighted_trimmed.columns[j+1]], 1),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives = predictions[predictions['true']==1]\n",
    "false_negatives = false_negatives[false_negatives['0s'] > 5]['0s']\n",
    "\n",
    "fn_result = pd.concat([false_negatives, X_i], axis=1, join='inner')\n",
    "fn_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_fn_X = scaler.fit_transform(fn_result.iloc[:,1:])\n",
    "weighted_values = np.multiply(scaled_fn_X, avg_coefs)\n",
    "fn_result_weighted = fn_result.copy()\n",
    "fn_result_weighted.iloc[:, 1:] = weighted_values\n",
    "# Drop the columns that don't have any evidence of influential values\n",
    "drop_cols = []\n",
    "for c in fn_result_weighted.columns:\n",
    "    if fn_result_weighted[c].max() - fn_result_weighted[c].min() < .5:\n",
    "        drop_cols.append(c)\n",
    "fn_result_weighted_trimmed = fn_result_weighted.drop(drop_cols, axis=1)\n",
    "fn_result_weighted_trimmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,20))\n",
    "im = ax.imshow(fn_result_weighted_trimmed.iloc[:,1:], cmap='viridis')\n",
    "ax.xaxis.tick_top()\n",
    "ax.set_xticks(np.arange(len(fn_result_weighted_trimmed.columns[1:])))\n",
    "ax.set_yticks(np.arange(len(fn_result_weighted_trimmed.index)))\n",
    "ax.set_xticklabels(fn_result_weighted_trimmed.columns[1:])\n",
    "labels = X_orig.loc[:,'school_name'].reindex([fn_result_weighted_trimmed.index])\n",
    "ax.set_yticklabels(labels)\n",
    "#ax.set_yticklabels(fn_result_weighted_trimmed.index)\n",
    "plt.setp(ax.get_xticklabels(), rotation=90, ha=\"left\", va=\"center\", rotation_mode=\"anchor\")\n",
    "\n",
    "for i in range(len(fn_result_weighted_trimmed.index)):\n",
    "    for j in range(len(fn_result_weighted_trimmed.columns[1:])):\n",
    "        text = ax.text(j, i, round(fn_result.loc[fn_result_weighted_trimmed.index[i], fn_result_weighted_trimmed.columns[j+1]], 1),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final ranking for PASSNYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just the columns of interest\n",
    "final_features = ['dbn',\n",
    "              'school_name',\n",
    "              'grade_7_enrollment',\n",
    "              'num_shsat_test_takers']\n",
    "# Convert the percent columns to proper floats\n",
    "pct_features = ['pct_test_takers',\n",
    "               'percent_black__hispanic']\n",
    "df_pct = np.multiply(X_orig[pct_features], .01)\n",
    "\n",
    "# Merge these columns to one DataFrame, along with number of 1 predictions and the true value\n",
    "df_final = pd.concat([X_orig[final_features], df_pct, predictions['1s'], predictions['true']], axis=1)\n",
    "\n",
    "# Determine the number of test takers this school would have needed to meet the median percentage of high_registrations\n",
    "median_pct = np.median(X_orig[y==1]['pct_test_takers'])/100\n",
    "predicted_test_takers = np.multiply(df_final['grade_7_enrollment'], median_pct)\n",
    "\n",
    "# Subtract the number of actual test takers from the hypothetical median number\n",
    "delta = predicted_test_takers - df_final['num_shsat_test_takers']\n",
    "\n",
    "# Multiply the delta by the minority percentage of the school to estimate how many minority students did not take the test\n",
    "df_final['minority_delta'] = np.round(np.multiply(delta, df_final['percent_black__hispanic']), 0)\n",
    "\n",
    "# Multiply the minority delta by the percentage of 1 votes to get a confidence-adjusted 'score', and sort by this.\n",
    "df_final['score'] = np.multiply(df_final['minority_delta'], df_final['1s']/10)\n",
    "df_final = df_final.sort_values(by='score', ascending=False)\n",
    "\n",
    "# Create a rank order column\n",
    "df_final.insert(0, 'rank', range(1,df_final.shape[0]+1))\n",
    "\n",
    "# Write to CSV\n",
    "df_final.to_csv('results/results.logreg.csv')\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
