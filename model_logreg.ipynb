{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Notebook\n",
    "[Return to project overview](final_project_overview.ipynb)\n",
    "\n",
    "### Andrew Larimer, Deepak Nagaraj, Daniel Olmstead, Michael Winton (W207-4-Summer 2018 Final Project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from util import our_train_test_split\n",
    "\n",
    "# set default options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned dataset\n",
    "merged_df = pd.read_csv('data_merged/combined_data_2018-07-18.csv')\n",
    "\n",
    "# Keep the numeric columns.\n",
    "features_to_keep = [\n",
    "                    'high_registrations',\n",
    "                    'district', \n",
    "                    'zip',\n",
    "                    'community_school', \n",
    "                    'economic_need_index', \n",
    "                    #'school_income_estimate',\n",
    "                    'percent_ell', \n",
    "                    'percent_asian', \n",
    "                    'percent_black', \n",
    "                    'percent_hispanic',\n",
    "                    'percent_black__hispanic', \n",
    "                    'percent_white', \n",
    "                    'student_attendance_rate',\n",
    "                    'percent_of_students_chronically_absent',\n",
    "                    'rigorous_instruction_percent', \n",
    "                    'rigorous_instruction_rating',\n",
    "                    'collaborative_teachers_percent', \n",
    "                    'collaborative_teachers_rating',\n",
    "                    'supportive_environment_percent', \n",
    "                    'supportive_environment_rating',\n",
    "                    'effective_school_leadership_percent',\n",
    "                    'effective_school_leadership_rating',\n",
    "                    'strong_family_community_ties_percent',\n",
    "                    'strong_family_community_ties_rating', \n",
    "                    'trust_percent', \n",
    "                    'trust_rating',\n",
    "                    'student_achievement_rating', \n",
    "                    'average_ela_proficiency',\n",
    "                    'average_math_proficiency', \n",
    "                    'grade_7_ela_all_students_tested',\n",
    "                    'grade_7_ela_4s_all_students',\n",
    "                    'grade_7_ela_4s_american_indian_or_alaska_native',\n",
    "                    'grade_7_ela_4s_black_or_african_american',\n",
    "                    'grade_7_ela_4s_hispanic_or_latino',\n",
    "                    'grade_7_ela_4s_asian_or_pacific_islander', \n",
    "                    'grade_7_ela_4s_white',\n",
    "                    'grade_7_ela_4s_multiracial',\n",
    "                    'grade_7_ela_4s_limited_english_proficient',\n",
    "                    'grade_7_ela_4s_economically_disadvantaged',\n",
    "                    'grade_7_math_all_students_tested', \n",
    "                    'grade_7_math_4s_all_students',\n",
    "                    'grade_7_math_4s_american_indian_or_alaska_native',\n",
    "                    'grade_7_math_4s_black_or_african_american',\n",
    "                    'grade_7_math_4s_hispanic_or_latino',\n",
    "                    'grade_7_math_4s_asian_or_pacific_islander', \n",
    "                    'grade_7_math_4s_white',\n",
    "                    'grade_7_math_4s_multiracial',\n",
    "                    'grade_7_math_4s_limited_english_proficient',\n",
    "                    'grade_7_math_4s_economically_disadvantaged',\n",
    "                    'number_of_students_english', \n",
    "                    'number_of_students_math',\n",
    "                    'number_of_students_science', \n",
    "                    'number_of_students_social_studies',\n",
    "                    'number_of_classes_english', \n",
    "                    'number_of_classes_math',\n",
    "                    'number_of_classes_science', \n",
    "                    'number_of_classes_social_studies',\n",
    "                    'average_class_size_english', \n",
    "                    'average_class_size_math',\n",
    "                    'average_class_size_science',\n",
    "                    'average_class_size_social_studies',\n",
    "                    'school_pupil_teacher_ratio'\n",
    "                   ]\n",
    "\n",
    "X = merged_df[features_to_keep]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split DataFrame into data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['high_registrations']\n",
    "X = X.drop(['high_registrations'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with NaNs\n",
    "Some columns have NaNs.  We'll try imputing these to the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values=np.nan, strategy='mean')\n",
    "X_i = pd.DataFrame(imp.fit_transform(X))\n",
    "X_i.columns = X.columns\n",
    "X_i.index = X.index\n",
    "X_i.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# one-hot encode these features as factors\n",
    "factor_cols = ['district', 'zip']\n",
    "\n",
    "# get indices for these columns\n",
    "factor_col_ids = []\n",
    "for f in factor_cols:\n",
    "    idx = X_i.columns.get_loc(f)\n",
    "    factor_col_ids.append(idx)\n",
    "factor_col_ids = np.array(factor_col_ids)\n",
    "\n",
    "print(X_i.shape)\n",
    "ohe_enc = OneHotEncoder(categorical_features=factor_col_ids, handle_unknown='ignore')\n",
    "X_ohe = ohe_enc.fit_transform(X_i)\n",
    "X_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos = X_i[y==1]\n",
    "X_neg = X_i[y==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import util\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = util.our_train_test_split(X_i, y, stratify = y)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "Find the optimal C-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "c_values = {'C': [0.010, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 1.000, 2.000, 3.000, 4.000]}\n",
    "for c in c_values['C']:\n",
    "    scaler = StandardScaler()\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "    log = LogisticRegression(C=c, penalty='l2', random_state=207)\n",
    "    log.fit(train_data_scaled, train_labels.values.ravel())\n",
    "    log_predicted_labels = log.predict(test_data_scaled)\n",
    "    log_f1 = metrics.f1_score(test_labels, log_predicted_labels, average='weighted')\n",
    "    log_accuracy = metrics.accuracy_score(test_labels, log_predicted_labels)\n",
    "    print(\"F1 score for C={}: {:.4f}    Accuracy: {:.4f}\".format(c, log_f1, log_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Pipeline and K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(C=1, penalty='l2', random_state=207))\n",
    "k_folds = 10\n",
    "cv_scores = cross_validate(pipe, train_data, train_labels, cv=k_folds, scoring=['accuracy','f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display accuracy with 95% confidence interval\n",
    "cv_accuracy = cv_scores['test_accuracy']\n",
    "print ('With %d-fold cross-validation, accuracy is: %.3f (95%% CI from %.3f to %.3f).' %\n",
    "       (k_folds, cv_accuracy.mean(), cv_accuracy.mean() - 1.96 * cv_accuracy.std(),\n",
    "        cv_accuracy.mean() + 1.96 * cv_accuracy.std()))\n",
    "\n",
    "# display F1 score with 95% confidence interval\n",
    "cv_f1 = cv_scores['test_f1']\n",
    "print ('The F1 score is: %.3f (95%% CI from %.3f to %.3f).' %\n",
    "       (cv_f1.mean(), cv_f1.mean() - 1.96 * cv_f1.std(),\n",
    "        cv_f1.mean() + 1.96 * cv_f1.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "scaler = StandardScaler()\n",
    "np_train_data = np.array(scaler.fit_transform(X_i))\n",
    "np_train_labels = np.array(y)\n",
    "folds = 5\n",
    "repeats = 10\n",
    "rskf = RepeatedStratifiedKFold(n_splits=folds, n_repeats= repeats, random_state=207)\n",
    "fold_list = []\n",
    "for f in range(1, (folds*repeats)+1):\n",
    "    fold_list.append('k{}'.format(f))\n",
    "coefs = pd.DataFrame(index=train_data.columns, columns=fold_list)\n",
    "predictions = pd.DataFrame(index=merged_df.index, columns = fold_list)\n",
    "counter = 1\n",
    "\n",
    "for train, test in rskf.split(np_train_data, np_train_labels):\n",
    "    log = LogisticRegression(C=1, penalty='l2', random_state=207)\n",
    "    log.fit(np_train_data[train], np_train_labels[train])\n",
    "    predicted_labels = log.predict(np_train_data[test])\n",
    "    coefs['k{}'.format(counter)] = log.coef_[0]\n",
    "    predictions.iloc[test, counter-1] = predicted_labels\n",
    "    counter += 1\n",
    "\n",
    "coefs['avg'] = coefs.mean(axis=1)\n",
    "sorted_coefs = coefs.sort_values(by='avg', ascending=False)\n",
    "sorted_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "### Most positively-influential features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top and bottom 5 most influential coefficients\n",
    "top_features, bottom_features = list(sorted_coefs.index[:6]), list(sorted_coefs.index[-6:])\n",
    "fig = plt.figure(figsize=(20,60))\n",
    "for c in top_features:\n",
    "    ax = fig.add_subplot(6,2,top_features.index(c)+1)\n",
    "    ax.set_title('Distribution for {}'.format(c), fontsize=17)\n",
    "    ax.hist(X_pos[c], bins=20, alpha=0.5, label=\"high registrants\", density=True)\n",
    "    ax.hist(X_neg[c], bins=20, alpha=0.5, label=\"low registrants\", density=True)\n",
    "    ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most negatively-influential features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,60))\n",
    "for c in bottom_features:\n",
    "    ax = fig.add_subplot(6,2,bottom_features.index(c)+1)\n",
    "    ax.set_title('Distribution for {}'.format(c), fontsize=17)\n",
    "    ax.hist(X_pos[c], bins=20, alpha=0.5, label=\"high registrants\", density=True)\n",
    "    ax.hist(X_neg[c], bins=20, alpha=0.5, label=\"low registrants\", density=True)\n",
    "    ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Wrong Answers\n",
    "We can build a table of all the kfold predictions, and see the degree to which the model got each school right or wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['1s'] = predictions.iloc[:,:50].sum(axis=1)\n",
    "predictions['0s'] = (predictions.iloc[:,:50]==0).sum(axis=1)\n",
    "predictions['true'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is perhaps most useful to examine the false positives - that is, schools that did NOT have high SHSAT registrations, but that the model thought SHOULD have.  We'll put the threshhold at 5 or more incorrect \"true\" classifications, and rank them in descending order (ie, the schools the model got most consistently wrong at the top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = predictions[predictions['true']==0]\n",
    "false_positives = false_positives[false_positives['1s'] >= 5].sort_values(by='1s', ascending=False)['1s']\n",
    "false_positives\n",
    "fp_result = pd.concat([false_positives, X_i.iloc[false_positives.index]], axis=1, join_axes=[false_positives.index])\n",
    "fp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine p-value for each value in the false positives group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_fp_X = scaler.fit_transform(fp_result.iloc[:,1:])\n",
    "avg_coefs = np.array(coefs['avg'])\n",
    "weighted_values = np.multiply(scaled_fp_X, avg_coefs)\n",
    "fp_result_weighted = fp_result.copy()\n",
    "fp_result_weighted.iloc[:, 1:] = weighted_values\n",
    "# Drop the columns that don't have any evidence of influential values\n",
    "drop_cols = []\n",
    "for c in fp_result_weighted.columns:\n",
    "    if fp_result_weighted[c].max() - fp_result_weighted[c].min() < .8:\n",
    "        drop_cols.append(c)\n",
    "fp_result_weighted_trimmed = fp_result_weighted.drop(drop_cols, axis=1)\n",
    "fp_result_weighted_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,18))\n",
    "im = ax.imshow(fp_result_weighted_trimmed.iloc[:,1:], cmap='viridis')\n",
    "ax.xaxis.tick_top()\n",
    "ax.set_xticks(np.arange(len(fp_result_weighted_trimmed.columns[1:])))\n",
    "ax.set_yticks(np.arange(len(fp_result_weighted_trimmed.index)))\n",
    "ax.set_xticklabels(fp_result_weighted_trimmed.columns[1:])\n",
    "ax.set_yticklabels(fp_result_weighted_trimmed.index)\n",
    "plt.setp(ax.get_xticklabels(), rotation=90, ha=\"left\", va=\"center\", rotation_mode=\"anchor\")\n",
    "\n",
    "for i in range(len(fp_result_weighted_trimmed.index)):\n",
    "    for j in range(len(fp_result_weighted_trimmed.columns[1:])):\n",
    "        text = ax.text(j, i, round(fp_result.loc[fp_result_weighted_trimmed.index[i], fp_result_weighted_trimmed.columns[j+1]], 1),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives = predictions[predictions['true']==1]\n",
    "false_negatives = false_negatives[false_negatives['0s'] > 5].sort_values(by='0s', ascending=False)['0s']\n",
    "false_negatives\n",
    "fn_result = pd.concat([false_negatives, X_i.iloc[false_negatives.index]], axis=1, join_axes=[false_negatives.index])\n",
    "fn_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_fn_X = scaler.fit_transform(fn_result.iloc[:,1:])\n",
    "weighted_values = np.multiply(scaled_fn_X, avg_coefs)\n",
    "fn_result_weighted = fn_result.copy()\n",
    "fn_result_weighted.iloc[:, 1:] = weighted_values\n",
    "# Drop the columns that don't have any evidence of influential values\n",
    "drop_cols = []\n",
    "for c in fn_result_weighted.columns:\n",
    "    if fn_result_weighted[c].max() - fn_result_weighted[c].min() < .8:\n",
    "        drop_cols.append(c)\n",
    "fn_result_weighted_trimmed = fn_result_weighted.drop(drop_cols, axis=1)\n",
    "fn_result_weighted_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,18))\n",
    "im = ax.imshow(fn_result_weighted_trimmed.iloc[:,1:], cmap='viridis')\n",
    "ax.xaxis.tick_top()\n",
    "ax.set_xticks(np.arange(len(fn_result_weighted_trimmed.columns[1:])))\n",
    "ax.set_yticks(np.arange(len(fn_result_weighted_trimmed.index)))\n",
    "ax.set_xticklabels(fn_result_weighted_trimmed.columns[1:])\n",
    "ax.set_yticklabels(fn_result_weighted_trimmed.index)\n",
    "plt.setp(ax.get_xticklabels(), rotation=90, ha=\"left\", va=\"center\", rotation_mode=\"anchor\")\n",
    "\n",
    "for i in range(len(fn_result_weighted_trimmed.index)):\n",
    "    for j in range(len(fn_result_weighted_trimmed.columns[1:])):\n",
    "        text = ax.text(j, i, round(fn_result.loc[fn_result_weighted_trimmed.index[i], fn_result_weighted_trimmed.columns[j+1]], 1),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
