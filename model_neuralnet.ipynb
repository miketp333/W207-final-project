{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Notebook\n",
    "[Return to project overview](final_project_overview.ipynb)\n",
    "\n",
    "\n",
    "### Andrew Larimer, Deepak Nagaraj, Daniel Olmstead, Michael Winton (W207-4-Summer 2018 Final Project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# set default options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and split class labels into separate array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from CSV\n",
    "df = pd.read_csv('data_merged/combined_data_2018-07-18.csv')\n",
    "\n",
    "# confirm dataset shape looks right\n",
    "print(df.shape)\n",
    "\n",
    "# this will show how many non-null values in each column\n",
    "df.info()\n",
    "\n",
    "# preview a few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create y variable with labels\n",
    "y = df['high_registrations']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and fit a \"naive\" model\n",
    "For the first model, we'll use all features except SHSAT-related features because they are too correlated with the way we calculated the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['dbn',\n",
    "             'num_shsat_test_takers',\n",
    "             'offers_per_student',\n",
    "             'pct_test_takers',\n",
    "             'high_registrations',\n",
    "             'school_name',\n",
    "#              'district',\n",
    "#              'zip',\n",
    "            ]\n",
    "\n",
    "# drop SHSAT-related columns\n",
    "X = df.drop(drop_cols, axis=1)\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values\n",
    "\n",
    "The sklearn estimators assume that all values in an array are numerical, and have meaning, so we need to replace `NaN` values.  We choose to use the column means for this imputation.\n",
    "\n",
    "> WARNING: this may be problematic for `school_income_estimate` (~2/3 of rows hold nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values by setting them to the column mean\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "X_imputed = imp.transform(X)\n",
    "\n",
    "# preview a few rows, post-processed\n",
    "print(X_imputed.shape)\n",
    "# confirm col 4 shouldn't be altered; NaNs should be replaced in col 5\n",
    "print(X_imputed[0:5,4:6])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding of categorical explanatory variables\n",
    "Columns such as zip code and school district ID, which are integeres should not be fed into an ML model as integers.  Instead, we need to treat them as factors and perform one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode these features as factors\n",
    "factor_cols = ['district', 'zip']\n",
    "\n",
    "# get indices for these columns\n",
    "factor_col_ids = []\n",
    "for f in factor_cols:\n",
    "    idx = df.columns.get_loc(f)\n",
    "    factor_col_ids.append(idx)\n",
    "factor_col_ids = np.array(factor_col_ids)\n",
    "\n",
    "print(X_imputed.shape)\n",
    "ohe_enc = OneHotEncoder(categorical_features=factor_col_ids, handle_unknown='ignore')\n",
    "X_ohe = ohe_enc.fit_transform(X_imputed)\n",
    "print(X_ohe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test sets\n",
    "\n",
    "Split into train (80%) and test (20%) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test sets; make sure to stratify\n",
    "X_train, X_test, y_train, y_test = util.our_train_test_split(X_ohe, y, stratify=y)\n",
    "\n",
    "# confirm stratification\n",
    "print('Frac positive class in training set = %.3f' % (np.sum(y_train==1) / len(y_train)))\n",
    "print('Frac positive class in test set = %.3f' % (np.sum(y_test==1) / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a \"naive\" multilayer perceptron model\n",
    "This first \"naive\" model uses all except for the SHSAT-related features, as described above.  We create a pipeline that will be used for k-fold cross-validation.  First, we scale the features, then estimate a multilayer perceptron neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline to run these in sequence\n",
    "n_features = X_train.shape[1]\n",
    "pipe_clf = make_pipeline(StandardScaler(with_mean=False), \n",
    "                   MLPClassifier(hidden_layer_sizes=(n_features,n_features,n_features), max_iter=500))\n",
    "\n",
    "# Do k-fold cross-validation, collecting both \"test\" accuracy and F1 \n",
    "k_folds=10\n",
    "cv_scores = cross_validate(pipe_clf, X_train, y_train, cv=k_folds, scoring=['accuracy','f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display accuracy with 95% confidence interval\n",
    "cv_accuracy = cv_scores['test_accuracy']\n",
    "print ('With %d-fold cross-validation, accuracy is: %.3f (95%% CI from %.3f to %.3f).' %\n",
    "       (k_folds, cv_accuracy.mean(), cv_accuracy.mean() - 1.96 * cv_accuracy.std(),\n",
    "        cv_accuracy.mean() + 1.96 * cv_accuracy.std()))\n",
    "\n",
    "# display F1 score with 95% confidence interval\n",
    "cv_f1 = cv_scores['test_f1']\n",
    "print ('The F1 score is: %.3f (95%% CI from %.3f to %.3f).' %\n",
    "       (cv_f1.mean(), cv_f1.mean() - 1.96 * cv_f1.std(),\n",
    "        cv_f1.mean() + 1.96 * cv_f1.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a \"race-blind\" multilayer perceptron model\n",
    "Because we know there's an existing bias problem in the NYC schools, in that the demographics of the test taking population have been getting more homogenous, and the explicit goal of PASSNYC is to make the pool more diverse, we want to train a model that excludes most demographic features.  This would enable us to train a \"race-blind\" model.  \n",
    "\n",
    "### Preprocess new X_train and X_test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_cols = ['percent_ell',\n",
    "             'percent_asian',\n",
    "             'percent_black',\n",
    "             'percent_hispanic',\n",
    "             'percent_black__hispanic',\n",
    "             'percent_white',\n",
    "             'economic_need_index',\n",
    "             'school_income_estimate']\n",
    "\n",
    "\n",
    "# drop additional (demographic) columns\n",
    "X_race_blind = X.drop(race_cols, axis=1)\n",
    "\n",
    "# impute missing values by setting them to the column mean\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X_race_blind)\n",
    "X_race_blind_imputed = imp.transform(X_race_blind)\n",
    "\n",
    "# one-hot encode these features as factors\n",
    "factor_cols = ['district', 'zip']\n",
    "\n",
    "# get indices for these columns\n",
    "factor_col_ids = []\n",
    "for f in factor_cols:\n",
    "    idx = X_race_blind.columns.get_loc(f)\n",
    "    factor_col_ids.append(idx)\n",
    "factor_col_ids = np.array(factor_col_ids)\n",
    "\n",
    "# perform one hot encoding\n",
    "ohe_enc = OneHotEncoder(categorical_features=factor_col_ids, handle_unknown='ignore')\n",
    "X_race_blind_ohe = ohe_enc.fit_transform(X_race_blind_imputed)\n",
    "\n",
    "# split into training and test sets; make sure to stratify\n",
    "X_train, X_test, y_train, y_test = util.our_train_test_split(X_race_blind_ohe, y, stratify=y)\n",
    "\n",
    "# confirm stratification\n",
    "print('Frac positive class in training set = %.3f' % (np.sum(y_train==1) / len(y_train)))\n",
    "print('Frac positive class in test set = %.3f' % (np.sum(y_test==1) / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline to run these in sequence\n",
    "n_features = X_train.shape[1]\n",
    "pipe_clf = make_pipeline(StandardScaler(with_mean=False), \n",
    "                   MLPClassifier(hidden_layer_sizes=(n_features,n_features,n_features), max_iter=500))\n",
    "\n",
    "# Do k-fold cross-validation, collecting both \"test\" accuracy and F1 \n",
    "k_folds=10\n",
    "cv_scores = cross_validate(pipe_clf, X_train, y_train, cv=k_folds, scoring=['accuracy','f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display accuracy with 95% confidence interval\n",
    "cv_accuracy = cv_scores['test_accuracy']\n",
    "print ('With %d-fold cross-validation, accuracy is: %.3f (95%% CI from %.3f to %.3f).' %\n",
    "       (k_folds, cv_accuracy.mean(), cv_accuracy.mean() - 1.96 * cv_accuracy.std(),\n",
    "        cv_accuracy.mean() + 1.96 * cv_accuracy.std()))\n",
    "\n",
    "# display F1 score with 95% confidence interval\n",
    "cv_f1 = cv_scores['test_f1']\n",
    "print ('The F1 score is: %.3f (95%% CI from %.3f to %.3f).' %\n",
    "       (cv_f1.mean(), cv_f1.mean() - 1.96 * cv_f1.std(),\n",
    "        cv_f1.mean() + 1.96 * cv_f1.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict = mlp.predict(X_test)\n",
    "\n",
    "# print(confusion_matrix(y_test,y_predict))\n",
    "# print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
