{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHSAT Test Results Merge Notebook\n",
    "[Return to project overview](final_project_overview.ipynb)\n",
    "\n",
    "### Andrew Larimer, Deepak Nagaraj, Daniel Olmstead, Michael Winton (W207-4-Summer 2018 Final Project)\n",
    "\n",
    "In this notebook, we will merge the data cleaned by the other \"prep_\" notebooks to create a single merged csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataframes, indexed by our primary key\n",
    "While school names may change or be input inconsistently, each school has a unique identifying DBN, sometimes referred to as a Location Code, to identify it. By importing each cleaned dataset with the DBN as the index, we are able to easily join them into a merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHSAT dataset: (589, 4)\n",
      "Class size dataset: (494, 13)\n",
      "Explorer dataset: (596, 49)\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets from CSV; when loading set index to the DBN column (to enforce uniqueness)\n",
    "shsat_df = pd.read_csv('data_cleaned/cleaned_shsat_outcomes.csv', index_col=\"dbn\")\n",
    "print('SHSAT dataset:',shsat_df.shape) # confirm that it's (589, 5)\n",
    "\n",
    "class_sizes_df = pd.read_csv('data_cleaned/cleaned_class_sizes.csv', index_col=\"DBN\")\n",
    "print('Class size dataset:', class_sizes_df.shape) # confirm that it's (494,13)\n",
    "\n",
    "explorer_df = pd.read_csv('data_cleaned/cleaned_explorer.csv', index_col=\"dbn\")\n",
    "print('Explorer dataset:', explorer_df.shape) # confirm that it's (596, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for duplicate entries.\n",
    "We do a quick check to make sure there are no duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True or False: there are duplicated indices within any dataframes?\n",
      "False.\n"
     ]
    }
   ],
   "source": [
    "shsat_dups = shsat_df.index.duplicated()\n",
    "class_sizes_dups = class_sizes_df.index.duplicated()\n",
    "explorer_dups = explorer_df.index.duplicated()\n",
    "                            \n",
    "print(\"True or False: there are duplicated indices within any dataframes?\")\n",
    "print(\"{0}.\".format(bool(sum(shsat_dups) + sum(class_sizes_dups) + sum(explorer_dups))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner joins for more complete data\n",
    "We'll use inner joins to select the intersection of our datasets, thus only selecting for schools for which we have data from each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Dataframe shape: (464, 66)\n"
     ]
    }
   ],
   "source": [
    "merged_df = shsat_df.join(explorer_df, how=\"inner\")\n",
    "merged_df = merged_df.join(class_sizes_df, how=\"inner\")\n",
    "print(\"Merged Dataframe shape:\",merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still leaves us with a merged dataframe of 464 rows and 66 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanitizing column names.\n",
    "To have consistent naming conventions across the column names, we'll replace spaces with underscores and lowercase the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having spaces etc. can cause annoying problems: replace with underscores\n",
    "def sanitize_column_names(c):\n",
    "    c = c.lower()\n",
    "    c = re.sub('[?,()/]', '', c)\n",
    "    c = re.sub('\\s-\\s', '_', c)\n",
    "    c = re.sub('[ -]', '_', c)\n",
    "    c = c.replace('%', 'percent')\n",
    "    return c\n",
    "\n",
    "merged_df.columns = [sanitize_column_names(c) for c in merged_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Density\n",
    "Let's take a look at how sparse our data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total empty cells: 99\n",
      "Percent null: 0.323%\n"
     ]
    }
   ],
   "source": [
    "print(\"Total empty cells:\",merged_df.isnull().sum().sum())\n",
    "print(\"Percent null: {0:.3f}%\".format(100*merged_df.isnull().sum().sum()/(merged_df.shape[0]*merged_df.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our worst offending rows and columns to see if anything stands out enough to be removed:\n",
    "\n",
    "#### Columns with Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_class_size_social_studies    19\n",
       "number_of_classes_social_studies     19\n",
       "number_of_students_social_studies    19\n",
       "average_class_size_english           10\n",
       "number_of_classes_english            10\n",
       "number_of_students_english           10\n",
       "average_math_proficiency              3\n",
       "average_ela_proficiency               3\n",
       "economic_need_index                   3\n",
       "average_class_size_math               1\n",
       "number_of_classes_math                1\n",
       "number_of_students_math               1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isnull().sum()[merged_df.isnull().sum() > 0]\\\n",
    "    .sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rows with Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "02M407    9\n",
       "02M312    6\n",
       "02M225    6\n",
       "02M255    6\n",
       "06M209    6\n",
       "02M413    6\n",
       "01M839    6\n",
       "15K839    6\n",
       "19K404    6\n",
       "17K484    6\n",
       "03M291    3\n",
       "01M188    3\n",
       "28Q358    3\n",
       "03M860    3\n",
       "08X562    3\n",
       "07X298    3\n",
       "03M859    3\n",
       "01M332    3\n",
       "19K678    3\n",
       "29Q355    3\n",
       "11X462    3\n",
       "13K265    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isnull().sum(axis=1)[merged_df.isnull().sum(axis=1) > 0]\\\n",
    "    .sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment we don't see any of these as being offending enough to be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a dated file\n",
    "\n",
    "To allow updates to the merged dataframe without disrupting work on models downstream until they are ready, we save a dated merged filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_data_2018-07-17.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the date to create the filename.\n",
    "d = datetime.date\n",
    "filename = \"combined_data_{0}.csv\".format( d.today().isoformat() )\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"data_merged/{0}\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
